import streamlit as st
from transformers import T5ForConditionalGeneration, T5Tokenizer
import torch

st.set_page_config(page_title="Grammar Correction App", layout="centered")
st.title("ğŸ“ Grammar Correction App")

# Load mÃ´ hÃ¬nh
@st.cache_resource
def load_model():
    model = T5ForConditionalGeneration.from_pretrained("vennify/t5-base-grammar-correction")
    tokenizer = T5Tokenizer.from_pretrained("vennify/t5-base-grammar-correction")
    return model, tokenizer

model, tokenizer = load_model()

# Giao diá»‡n nháº­p liá»‡u
input_text = st.text_area("âœï¸ Nháº­p Ä‘oáº¡n vÄƒn tiáº¿ng Anh báº¡n muá»‘n sá»­a ngá»¯ phÃ¡p:", height=150)

if st.button("ğŸ”§ Sá»­a ngá»¯ phÃ¡p"):
    if not input_text.strip():
        st.warning("Vui lÃ²ng nháº­p má»™t Ä‘oáº¡n vÄƒn báº£n trÆ°á»›c khi nháº¥n sá»­a.")
    else:
        input_text = "grammar: " + input_text

        input_ids = tokenizer.encode(input_text, return_tensors="pt", max_length=512, truncation=True)
        with torch.no_grad():
            outputs = model.generate(input_ids, max_length=512, num_beams=4, early_stopping=True)
        corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

        st.success("âœ… Äoáº¡n vÄƒn Ä‘Ã£ Ä‘Æ°á»£c sá»­a:")
        st.write(corrected_text)
